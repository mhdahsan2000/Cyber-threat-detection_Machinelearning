{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a729807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn import preprocessing \n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bbcbb",
   "metadata": {},
   "source": [
    "This code is submitted as part of project 2 for the subject COMP90037 (Security Analytics) at the University of  Melbourne .\n",
    "     \n",
    "    -------------------------------------------\n",
    "    COMP90037 Security Analytics - Project 2 \n",
    "    Machine learning based Threat detection\n",
    "\n",
    "    Author : Mohammed Ahsan Kollathodi \n",
    "    Student id: 1048942.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee259b",
   "metadata": {},
   "source": [
    "### The principal aim of this code is to perform pre-processing to the given dataset to clean dataset or remove noise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fede487f",
   "metadata": {},
   "source": [
    "### Train data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4907fc5",
   "metadata": {},
   "source": [
    "The dataset provided contain the NetFlow data for a network under cyberattacks. Each line of the dataset includes the following 15 fields: (1) stream ID, (2) timestamp, (3) duration, (4) protocol, (5) source IP address, (6) source port, (7) direction, (8) destination IP address, (9) destination port, (10) state, (11) source type of service, (12) destination type of service, (13) the number of total packets, (14) the number of bytes transferred in both directions, (15) the number of bytes transferred from the source to the destination.\n",
    "\n",
    "I have not labelled stream ID as it's not very relevant with respect to the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc5de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train dataframe.\n",
    "train_df = pd.read_csv('trainingdata_cleaned.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1731e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test dataframe. \n",
    "test_df = pd.read_csv('testdata_cleaned.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffdddd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The features are treated as an unique dataframe with different keys. \n",
    "selected_features = pd.concat([train_df,test_df], keys=['train','test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b4f887b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to scale the numerical features. \n",
    "numerical_features = selected_features[['num_total_packets','total_bytes','src_bytes','packets_in_Sec','bytes_total_in_Sec','Source_Bytes_Sec']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe37c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ahsan/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py:5233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().replace(\n"
     ]
    }
   ],
   "source": [
    "numerical_features.replace([np.inf,np.nan], -1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19e87b97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "num_total_packets     False\n",
       "total_bytes           False\n",
       "src_bytes             False\n",
       "packets_in_Sec        False\n",
       "bytes_total_in_Sec    False\n",
       "Source_Bytes_Sec      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_features.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55466536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler() \n",
    "scaler.fit(numerical_features.loc['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6f1bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_numerical_df = pd.DataFrame(scaler.transform(numerical_features.loc['train']), columns=numerical_features.columns,\n",
    "                                   index=numerical_features.loc['train'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "447edbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numerical_df = pd.DataFrame(scaler.transform(numerical_features.loc['test']), columns=numerical_features.columns,\n",
    "                                   index=numerical_features.loc['test'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef3bb0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the categorical features we employ the label encoder.\n",
    "categorical_features = selected_features[['protocol', 'src_ip', 'src_port','direction',\n",
    "                         'dst_ip', 'dst_port', 'state', 'srctype_service','dsttype_service']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a25dc1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "protocol\n",
      "src_ip\n",
      "src_port\n",
      "direction\n",
      "dst_ip\n",
      "dst_port\n",
      "state\n",
      "srctype_service\n",
      "dsttype_service\n"
     ]
    }
   ],
   "source": [
    "encoderset = {}\n",
    "\n",
    "for column in categorical_features :\n",
    "    print(column)\n",
    "    encoderset[column] = preprocessing.LabelEncoder()\n",
    "    encoderset[column].fit(categorical_features[column].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7814ff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_categorical_dataframe = categorical_features.loc['test'].apply(lambda x: encoderset[x.name].transform(categorical_features.loc['test'][x.name].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44802b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_categorical_dataframe = categorical_features.loc['train'].apply(lambda x: encoderset[x.name].transform(categorical_features.loc['train'][x.name].astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "393f7b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We then join together the numerical and the categorical data. \n",
    "data_train = pd.concat([train_numerical_df, train_categorical_dataframe], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "473f211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the output to CSV. \n",
    "data_train.to_csv('train_data_of_A1.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19373862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test data would comprise of the concatenated numerical and categorical data. \n",
    "data_test = pd.concat([test_numerical_df, test_categorical_dataframe], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f7f256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the test data into output CSV.\n",
    "data_test.to_csv('test_data_of_A1.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01131639",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
